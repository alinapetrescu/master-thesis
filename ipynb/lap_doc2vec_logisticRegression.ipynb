{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour que l'apprentissage par ML soit faisable, on sélectionne les **catégories significatives** avec un \"grand\" nombre d'exposés des faits associés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La démarche proposée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on a créé ***déjà*** des modèles Doc2Vec abstraits\n",
    "- on leur a associé comme vocabulaire les exposés déjà labélisés (avec comme tags les catégories présentes déjà dans la base de données et certains exposés peuvent apparaître plusieurs fois avec une même catégorie ou avec des catégories différentes)\n",
    "- on a entraîné ces modèles avec comme documents les ***exposés des faits ayant comme tags les noms des catégories associées dans la base de données*** => on a obtenu autant de vecteurs numériques que de catégories distinctes\n",
    "- ***maintenant***, avec les modèles Doc2Vec (entrainés), on infère les vecteurs numériques associés aux exposés des faits à classifier (on réalise l'embedding) pour tous les exposés et on garde comme classes (labels) pour la suite les \"bonnes\" catégories (mentionnées dans la base de données)\n",
    "- avec tous ces vecteurs vus comme des vecteurs de features, on fait la classification supervisée grâce à des modèles LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr')\n",
    "spacy.load('en')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des modèles Doc2Vec entraînés et sauvés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 2 modèles ci-dessous correspondent à l'embedding (à la vectorisation) des edf à l'aide de la librairie Doc2Vec :\n",
    "- **model_dbow_300** utilise l'algorithme DBOW, une taille de vecteurs de 300 features et a été entraîné 30 epochs\n",
    "- **model_dm_300** utilise l'algorithme DM, une taille de vecteurs de 300 features et a été entraîné 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow_300 = Doc2Vec.load(\"model_dbow_300_61.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm_300 = Doc2Vec.load(\"model_dm_300_61.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l_main_cats** est une liste avec les catégories principales, i.e. avec plus de 1000 exposés associés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('l_main_cats_61', 'rb') as f:\n",
    "    l_main_cats = pickle.load(f)\n",
    "#print(len(l_main_cats))\n",
    "#print(l_main_cats[:3])\n",
    "#print(l_main_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ll_merged_cats** est la liste de liste qui regroupe les catégories principales semblables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[['ACCIDENT - DE CIRCULATION - DEGATS MATERIEL', 'AR - DIVERS', 'INFRACTION - LCR', 'AR - PANNE - VEHICULE', 'CIRCULATION - ROUTIERE', 'AR - ACCIDENT', 'ACCIDENT - DE CIRCULATION - AVEC FUITE', 'ACCIDENT - DE CIRCULATION - AVEC BLESSE', 'ACCIDENT - DE CIRCULATION - AVEC ANIMAL', 'VEHICULE - SUSPECT', 'VEHICULE'], ['TAPAGE NOCTURNE', 'TROUBLE - DE LA TRANQUILLITE / NUISANCE', 'BRUIT'], ['VOL - PAR EFFRACTION', 'VOL', \"VOL - A L'ETALAGE\"], ['INDIVIDU - SUSPECT', 'INDIVIDU - PERTURBE', \"FUITE - D'UN LIEU DE PLACEMENT\"], ['OPERATION', 'REVOCATION', 'APPREHENSION / ARRESTATION', 'COLLABORATION - INTERPOLICE', 'DEMANDE - IDENTIFICATION'], ['BAGARRE', 'LITIGE', 'VIOLENCE - DOMESTIQUE'], [\"DEMANDE - D'AMBULANCE\", \"DEMANDE - D'ASSISTANCE\"], ['ANIMAUX', 'INCENDIE', 'DROGUE', 'MINEUR - IMPLIQUE', 'TENTATIVE', 'DOMMAGES - A LA PROPRIETE', 'INDESIRABLE']]\n"
     ]
    }
   ],
   "source": [
    "with open('ll_merged_cats_61', 'rb') as f:\n",
    "    ll_merged_cats = pickle.load(f)\n",
    "print(len(ll_merged_cats))\n",
    "print(ll_merged_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l_merged_catNoms** est une liste avec les noms des catégories principales regroupées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['CIRCULATION', 'TROUBLE', 'VOLS', 'INDIVIDU', 'INTERVENTION', 'DISPUTE', 'DEMANDE', 'DIVERS']\n"
     ]
    }
   ],
   "source": [
    "with open('l_merged_catNoms_61', 'rb') as f:\n",
    "    l_merged_catNoms = pickle.load(f)\n",
    "print(len(l_merged_catNoms))\n",
    "print(l_merged_catNoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**main_efs** est le DataFrame contenant les exposés (et leurs catégories) associés aux catégories \"principales\" (avec plus de 1000 edf correspondants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_efs = pd.read_csv('/home/alina/UNIFR/TM/random/ExposesDesFaits/main_efs_61.csv', header=0, sep=';')\n",
    "#main_efs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**merged_main_efs** est la base de données dans laquelle on a ajouté la colonne supplémentaire pour le regroupement des catégories principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPOSES</th>\n",
       "      <th>CATEGORIE</th>\n",
       "      <th>MERGED_CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un renard sur la voie gauche.</td>\n",
       "      <td>ANIMAUX</td>\n",
       "      <td>DIVERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bras cassé suite glissade sur le verglas.</td>\n",
       "      <td>DEMANDE - D'AMBULANCE</td>\n",
       "      <td>DEMANDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demande d'ambulance pour un jeune qui a trop b...</td>\n",
       "      <td>DEMANDE - D'AMBULANCE</td>\n",
       "      <td>DEMANDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Un véhicule noire, plaques AI commençant évent...</td>\n",
       "      <td>ACCIDENT - DE CIRCULATION - AVEC FUITE</td>\n",
       "      <td>CIRCULATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>panne moteur</td>\n",
       "      <td>AR - PANNE - VEHICULE</td>\n",
       "      <td>CIRCULATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             EXPOSES  \\\n",
       "0                      Un renard sur la voie gauche.   \n",
       "1          Bras cassé suite glissade sur le verglas.   \n",
       "2  Demande d'ambulance pour un jeune qui a trop b...   \n",
       "3  Un véhicule noire, plaques AI commençant évent...   \n",
       "4                                       panne moteur   \n",
       "\n",
       "                                CATEGORIE   MERGED_CAT  \n",
       "0                                 ANIMAUX       DIVERS  \n",
       "1                   DEMANDE - D'AMBULANCE      DEMANDE  \n",
       "2                   DEMANDE - D'AMBULANCE      DEMANDE  \n",
       "3  ACCIDENT - DE CIRCULATION - AVEC FUITE  CIRCULATION  \n",
       "4                   AR - PANNE - VEHICULE  CIRCULATION  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_main_efs = pd.read_csv('/home/alina/UNIFR/TM/random/ExposesDesFaits/merged_main_efs_61.csv', header=0, sep=';')\n",
    "merged_main_efs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans la base de données, il y a 122204 enregistrements.\n"
     ]
    }
   ],
   "source": [
    "print('Dans la base de données, il y a', merged_main_efs.shape[0], 'enregistrements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite, on fait une classification supervisée grâce à la logistic regression. \n",
    "\n",
    "L'ensemble de données de départ est formé par : \n",
    "- les vecteurs numériques (feature vectors) obtenus par l'embedding des exposés des faits à l'aide du modèle Doc2Vec\n",
    "- les tags assoiés aux feature vectors (en fait les catégories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données (d'entraînement et de test) pour le modèle LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l_expos** est la liste des exposés des faits dont la catégorie associée est une des catégories \"principales\" (avec plus de 1000 edf correspondants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Un renard sur la voie gauche.',\n",
       " 'Bras cassé suite glissade sur le verglas.',\n",
       " \"Demande d'ambulance pour un jeune qui a trop bu et qui ne se réveille pas. Appel transféré au 144.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_expos = list(merged_main_efs['EXPOSES'])\n",
    "l_expos[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l_cats** est la liste des catégories associées aux exposés des faits de la liste **l_expos** (dans le même ordre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIVERS', 'DEMANDE', 'DEMANDE']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_cats = list(merged_main_efs['MERGED_CAT'])\n",
    "l_cats[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l_couples_expo_cat** est la liste des couples dont le premier élément est un exposé de faits et le deuxième élément est la catégorie qui lui est associée (dans la base de donnée princiapale **main_efs**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Un renard sur la voie gauche.', 'DIVERS'),\n",
       " ('Bras cassé suite glissade sur le verglas.', 'DEMANDE'),\n",
       " (\"Demande d'ambulance pour un jeune qui a trop bu et qui ne se réveille pas. Appel transféré au 144.\",\n",
       "  'DEMANDE')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_couples_expo_cat = list(zip(l_expos, l_cats))\n",
    "l_couples_expo_cat[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l_couples_expo_cat_rand** est obtenu par la randomization de la liste **l_couples_expo_cat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La liste originale : \n",
      " [('Un renard sur la voie gauche.', 'DIVERS'), ('Bras cassé suite glissade sur le verglas.', 'DEMANDE'), (\"Demande d'ambulance pour un jeune qui a trop bu et qui ne se réveille pas. Appel transféré au 144.\", 'DEMANDE')]\n",
      "\n",
      "La liste après la randomization non in place : \n",
      " [('une biche morte dans le champ ', 'DIVERS'), ('Dame très âgée désorientée.', 'DEMANDE'), (\"Affaire provenant de réception HP: L'informatrice avait laissé sa valise chez sa soeur. Cette dernière n'habite plus l'appartement et à laissé sa valise sur place. Le nouveau locataire refuse de lui rendre sa valise. Va sur place et nous rappelle.\", 'DEMANDE')]\n"
     ]
    }
   ],
   "source": [
    "l_couples_expo_cat_rand = random.sample(l_couples_expo_cat, len(l_couples_expo_cat))\n",
    "print (\"La liste originale : \\n\",  l_couples_expo_cat[:3])\n",
    "print (\"\\nLa liste après la randomization non in place : \\n\",  l_couples_expo_cat_rand[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare (graĉe à la fonction **train_test_split**) l'ensemble des couples **l_couples_expo_cat_rand** en 2 sous-ensembles : un pour l'entraînement (90%) avec le suffixe **train** et l'autre pour le test (10%) avec le suffixe **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_couples_expo_cat_train, l_couples_expo_cat_test = \\\n",
    "            train_test_split(l_couples_expo_cat_rand, test_size=0.1, random_state=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 122204 enregistrements ont été divisés en 109983 enregistrements pour l'entraînement et 12221 enregistrements pour le test.\n"
     ]
    }
   ],
   "source": [
    "print('Les', len(l_couples_expo_cat_rand), 'enregistrements ont été divisés en', \n",
    "      len(l_couples_expo_cat_train), 'enregistrements pour l\\'entraînement et', \n",
    "      len(l_couples_expo_cat_test), 'enregistrements pour le test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait les exposés pour l'entraînement et pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_expos_train = [expo for expo, cat in l_couples_expo_cat_train]\n",
    "l_expos_test = [expo for expo, cat in l_couples_expo_cat_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait les catégories pour l'entraînement et pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cats_train = [cat for expo, cat in l_couples_expo_cat_train]\n",
    "l_cats_test = [cat for expo, cat in l_couples_expo_cat_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'embedding en vue de la classification LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à l'un des modèles Doc2Vec déjà entraînés, on peut faire l'embedding, i.e. calculer le vecteur numérique (feature vector), pour n'importe quel exposé des faits (qui fait partie ou pas de l'ensemble d'entraînement du modèle Doc2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **edf2vec** reçoit comme paramètres:\n",
    "- **expo** l'exposé des faits à vectoriser\n",
    "- **model_d2v** le modèle Doc2Vec qui va inférer le vecteur numérique (feature vector)\n",
    "- **epochs** le nombre d'itérations durant l'entraînement du nouveau document\n",
    "- **seed** le \"seed\" pour la génération de nombres aléatoires pour le model Doc2Vec utilisé \n",
    "\n",
    "et elle retourne le nouveau feature vector dont la dimension est celle prévue par le modèle qui infère.\n",
    "\n",
    "Remarque : des appels successifs de la méthode prédéfinie **infer_vector** peuvent retourner des vecteurs numériques différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edf2vec(expo, model_d2v, epochs=None, seed=8017):\n",
    "    if epochs is None:\n",
    "        epochs=model_d2v.epochs\n",
    "    blob = tb(expo.lower())\n",
    "    doc_words = list(blob.words)\n",
    "    spacy_stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
    "    # on élimine les stop words\n",
    "    doc_words = [elem for elem in doc_words if elem not in spacy_stop_words]\n",
    "    # on élimine les mots contenant au moins un chiffre\n",
    "    doc_words = [elem for elem in doc_words if not any(c.isdigit() for c in elem)]\n",
    "    # on élimine les mots formés d'un seul caractère\n",
    "    doc_words = [elem for elem in doc_words if len(elem) > 1]\n",
    "    #print(doc_words)\n",
    "    model_d2v.random.seed(seed)\n",
    "    v = model_d2v.infer_vector(doc_words, epochs)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des modèles LogisticRegression abstrait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque modèle Doc2Vec, on crée un modèle abstrait de type LogisticRegression (et les 2 modèles abstraits sont identiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_dbow_300 = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_dm_300 = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrétisation des modèles abstraits et évaluation de leurs performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut associer au modèle abstrait les données d'entraînement (training data), à savoir :\n",
    "- l'ensemble de vecteurs d'entraînement (training vectors) représenté par une matrice (tableau bidimensionnel) ayant comme lignes les feature vectors calculés pour les exposés des faits grâce au modèle (entraîné) Doc2Vec\n",
    "- le vecteur avec les labels (target vector) représenté par la liste **l_labels** contenant les tags pour les exposés des faits (dans le même ordre que celui de l'ensemble de vecteurs d'entraînement)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait l'embedding (la vectorisation), donc on calcule (on infère) les vecteurs numériques pour l'**entraînement** et pour le **test** pour chacun des 2 modèles Doc2Vec (grâce à la méthode ad-hoc edf2vec qui fait appel à la méthode standard infer_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 203 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vects_train_dbow_300 = [edf2vec(expo, model_dbow_300) for expo in l_expos_train]\n",
    "vects_test_dbow_300 = [edf2vec(expo, model_dbow_300) for expo in l_expos_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vects_train_dbow_300[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 183 ms, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vects_train_dm_300 = [edf2vec(expo, model_dm_300) for expo in l_expos_train]\n",
    "vects_test_dm_300 = [edf2vec(expo, model_dm_300) for expo in l_expos_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vects_train_dm_300[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On entraîne les 2 modèles LR abstraits** (identiques) avec les vecteurs numériques et les labels d'entraînement (suffixe **train**) correspondants à chaque modèle Doc2Vec \n",
    "\n",
    "L'entraînement se fait grâce à la méthode **fit** et suite à son appel, le modèle abstrait appelant la méthode devient un modèle entraîné\n",
    "\n",
    "Par la suite, le modèle entraîné sera capable de faire des prédiction pour les catégories (les classes) grâce aux méthodes **predict()** et **predict_proba()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 279 ms, sys: 1.5 s, total: 1.78 s\n",
      "Wall time: 7min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=-1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_lr_dbow_300.fit(vects_train_dbow_300, l_cats_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 364 ms, sys: 749 ms, total: 1.11 s\n",
      "Wall time: 7min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=-1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_lr_dm_300.fit(vects_train_dm_300, l_cats_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec chacun des modèles LR entraînés, **on prédit les catégories** (les classes ou les labels) pour les vecteurs numériques de test\n",
    "\n",
    "En fait, appelée avec une matrice dont les lignes sont les feature vectors à classifier, la méthode **predict** retourne un array  avec autant d'éléments que de lignes dans la matrice et dont chaque élément représente la classe (chez nous la catégorie) la plus probable pour le feature vector correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cats_pred_dbow_300 = model_lr_dbow_300.predict(vects_test_dbow_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cats_pred_dm_300 = model_lr_dm_300.predict(vects_test_dm_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On calcule les performances** de chacun des 2 modèles LR grâce à des fonctions prévues à cet effet dans la librairie ***sklearn.metrics***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy pour le modèle dbow_300 : 0.6974879306112429\n",
      "Le score F1 pour le modèle dbow_300 : 0.6935074807805897\n",
      "La precision pour le modèle dbow_300 : 0.6925520945398996\n",
      "Le recall pour le modèle dbow_300 : 0.6974879306112429\n"
     ]
    }
   ],
   "source": [
    "print('L\\'accuracy pour le modèle dbow_300 :', accuracy_score(l_cats_test, l_cats_pred_dbow_300))\n",
    "print('Le score F1 pour le modèle dbow_300 :', f1_score(l_cats_test, l_cats_pred_dbow_300, average='weighted'))\n",
    "print('La precision pour le modèle dbow_300 :', precision_score(l_cats_test, l_cats_pred_dbow_300, average='weighted'))\n",
    "print('Le recall pour le modèle dbow_300 :', recall_score(l_cats_test, l_cats_pred_dbow_300, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy pour le modèle dm_300 : 0.5619834710743802\n",
      "Le score F1 pour le modèle dm_300 : 0.5410531131402272\n",
      "La precision pour le modèle dm_300 : 0.5599675228795\n",
      "Le recall pour le modèle dm_300 : 0.5619834710743802\n"
     ]
    }
   ],
   "source": [
    "print('L\\'accuracy pour le modèle dm_300 :', accuracy_score(l_cats_test, l_cats_pred_dm_300))\n",
    "print('Le score F1 pour le modèle dm_300 :', f1_score(l_cats_test, l_cats_pred_dm_300, average='weighted'))\n",
    "print('La precision pour le modèle dm_300 :', precision_score(l_cats_test, l_cats_pred_dm_300, average='weighted'))\n",
    "print('Le recall pour le modèle dm_300 :', recall_score(l_cats_test, l_cats_pred_dm_300, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier les valeurs obtenues pour l'accuracy en appelant la méthode **score** pour chaque modèle LR déjà entraînée (à la place de la fonction **accuracy_score** du package sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy pour le modèle dbow_300 : 0.6974879306112429\n"
     ]
    }
   ],
   "source": [
    "print('L\\'accuracy pour le modèle dbow_300 :', model_lr_dbow_300.score(vects_test_dbow_300, l_cats_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy pour le modèle dm_300 : 0.5619834710743802\n"
     ]
    }
   ],
   "source": [
    "print('L\\'accuracy pour le modèle dm_300 :', model_lr_dm_300.score(vects_test_dm_300, l_cats_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, on peut aussi calculer la matrice de confusion qui est une matrice carrée dont les lignes correspondent aux catégories réelles (de la base de données) et les colonnes correspondent aux catégories prédites (par le modèle LR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3242   86    8  104   43   39   12   45]\n",
      " [ 160 1146  113  201  132   35   68   97]\n",
      " [  18  150  345   51   16   13   19   27]\n",
      " [ 177  166   31 1186  106   87   38  170]\n",
      " [  66  213   27  102  509  106   28   82]\n",
      " [  80   59   23   59   94  651    2   81]\n",
      " [  18   38   13   45    8    8  756   24]\n",
      " [  67   66    6   87   26   42   15  689]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_test_dbow_300 = confusion_matrix(l_cats_test, l_cats_pred_dbow_300)\n",
    "print(conf_matrix_test_dbow_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3579 1952  639 1961 1133 1049  910  998]\n"
     ]
    }
   ],
   "source": [
    "l_tot_lines = np.sum(conf_matrix_test_dbow_300, axis=1)\n",
    "print(l_tot_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12221"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_tot_lines.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3166  151    1  134   27   33   20   47]\n",
      " [ 488  946   48  234   74   66   62   34]\n",
      " [ 142  186  168   67   12   19   32   13]\n",
      " [ 598  232   13  828   54   79   53  104]\n",
      " [ 254  259    6  160  294   82   29   49]\n",
      " [ 333  118    7   85   53  405    4   44]\n",
      " [ 105   71    5   89    4    7  617   12]\n",
      " [ 241   77    5  135   27   47   22  444]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_test_dm_300 = confusion_matrix(l_cats_test, l_cats_pred_dm_300)\n",
    "print(conf_matrix_test_dm_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion est une matrice carrée dont les lignes correspondent aux catégories réelles et les colonnes correspondent aux catégories prédites.\n",
    "\n",
    "Dans la matrice de confusion:\n",
    "- Sur la diagonale principale, on trouve tous les TP (true positive)\n",
    "    - par exemple, dans la cellule d'indices i=j=5, se trouve le nombre d'edf qui ont été prédits comme appartenant à la catégorie 5 et qui appartenaient en réalité aussi à la catégorie 5\n",
    "- Sur une ligne, toutes les cellules à part celle sur la diagonale principale contiennent des F (false) qui peuvent être interprêtés comme des FN (false negative)\n",
    "    - par exemple, dans la celule d'indices i=3 et j=2, se trouve le nombre d'edf qui appartiennent en réalité à la catégorie 3, mais qui ont été prédits comme appartenant à la catégorie 2\n",
    "- Sur une colonne, toutes les cellules à part celle sur la diagonale principale contiennent des F (false) qui peuvent être interprêtés comme des FP (false positive)\n",
    "    - par exemple, dans la celule d'indices i=3 et j=2, se trouve le nombre d'edf qui appartiennent en réalité à la catégorie 3, mais qui ont été prédits comme appartenant à la catégorie 2\n",
    "    \n",
    "De plus:\n",
    "- la somme de toutes les cellules situées sur une même ligne donne le nombre d'edf qui en réalité ont comme type la catégorie correspondante à cette ligne\n",
    "    - par exemple, la somme de toutes les cellules situées sur la ligne 3 correspond au nombre d'edf qui appartiennent en réalité à la catégorie 3\n",
    "- la somme de toutes les cellules situées sur une même colonne donne le nombre d'edf qui ont été prédits comme appartenant à la catégorie correspondante à cette colonne\n",
    "    - par exemple, la somme de toutes les cellules situées sur la colonne 2 correspond au nombre d'edf qui ont été prédits comme appartenant à la catégorie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ordre dans lequel les catégories sont prises en compte par le modèle LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_lr_dbow_300.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('La première ligne \\n', conf_matrix_test_dbow_300[0,])\n",
    "print('\\n La première colonne \\n', conf_matrix_test_dbow_300[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interprétation de la première ligne :\n",
    "- (cellule 0,0) 153 edf ont dans la base de données la catégorie 'ACCIDENT - DE CIRCULATION - AVEC ANIMAL' et ont été prédites correctement\n",
    "- (cellule 0,3) 4 edf ont dans la base de données la catégorie 'ACCIDENT - DE CIRCULATION - AVEC ANIMAL' et ont été prédites comme 'ACCIDENT - DE CIRCULATION - DEGATS MATERIEL'\n",
    "- (cellule 0,4) 8 edf ont dans la base de données la catégorie 'ACCIDENT - DE CIRCULATION - AVEC ANIMAL' et ont été prédites comme 'ANIMAUX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interprétation de la première colonne :\n",
    "- (cellule 0,0) 153 edf ont été prédits dans la catégorie 'ACCIDENT - DE CIRCULATION - AVEC ANIMAL' et ils ont dans la base de données la même catégorie\n",
    "- (cellule 3,0) 4 edf ont été prédits dans la catégorie 'ACCIDENT - DE CIRCULATION - AVEC ANIMAL' et ils ont dans la base de données la catégorie 'ACCIDENT - DE CIRCULATION - DEGATS MATERIEL'\n",
    "- (cellule 4,0) 13 edf ont été prédits dans la catégorie 'ACCIDENT - DE CIRCULATION - AVEC ANIMAL' et ils ont dans la base de données la catégorie 'ANIMAUX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarque importante\n",
    "- l'étude de la première ligne et de la première colonne de la matrice de confusion met en évidence que les catégories **'ACCIDENT - DE CIRCULATION - AVEC ANIMAL'** et les catégories **'ACCIDENT - DE CIRCULATION - DEGATS MATERIEL'** et **'ANIMAUX'** produisent des confusions (sont difficilement distinguables et un même exposé pourrait être mis à juste titre dans 2 catégories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vects_train_dbow_dm = [np.array(list(vects_train_dbow_300[i])+list(vects_train_dm_300[i])) \n",
    "                       for i in range(len(vects_train_dbow_300))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "vects_test_dbow_dm = [np.array(list(vects_test_dbow_300[i])+list(vects_test_dm_300[i])) \n",
    "                       for i in range(len(vects_test_dbow_300))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vects_train_dbow_dm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_dbow_dm = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 576 ms, sys: 6.28 s, total: 6.86 s\n",
      "Wall time: 14min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=-1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_lr_dbow_dm.fit(vects_train_dbow_dm, l_cats_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cats_pred_dbow_dm = model_lr_dbow_dm.predict(vects_test_dbow_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy pour le modèle dbow_dm : 0.7220358399476311\n"
     ]
    }
   ],
   "source": [
    "print('L\\'accuracy pour le modèle dbow_dm :', accuracy_score(l_cats_test, l_cats_pred_dbow_dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy pour le modèle dbow_dm : 0.7220358399476311\n"
     ]
    }
   ],
   "source": [
    "print('L\\'accuracy pour le modèle dbow_dm :', model_lr_dbow_dm.score(vects_test_dbow_dm, l_cats_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction pour un nouvel exposé des faits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour prédire la \"bonne\" catégorie pour un nouvel exposé des faits :\n",
    "- d'abord, on crée un modèle abstrait LogisticRegression et on l'entraîne avec des vecteurs numériques (obtenus grâce à un modèle Doc2Vec) et des labels correspondants\n",
    "- ensuite, on calcule le vecteur numérique (feature vector) correspondant au nouvel exposé grâce à l'embedding (ou la vectorisation) réalisé(e) avec le (même) modèle Doc2Vec\n",
    "- finalement, on prédit la \"bonne\" catégorie grâce au modèle LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création et entraînement d'un modèle logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée de nouveaux modèles abstraits LR avec le suffixe **fin** (basés ensuite sur les modèles Doc2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_dbow_300_fin = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_dm_300_fin = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'entraîner ces modèles abstraits LR, on utilise comme ensemble de vecteurs numériques d'entraînement les vecteurs numériques inférés par les modèles Doc2Vec pour ***tous*** les exposés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_dbow_300_fin = [edf2vec(expo, model_dbow_300) for expo,cat in l_couples_expo_cat_rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_dm_300_fin = [edf2vec(expo, model_dm_300) for expo,cat in l_couples_expo_cat_rand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**y_fin** est le vecteur cible (target vector) contenant les catégories (labels) correspondants à l'ensemble d'entraînement et ce vecteur est le même pour tous les 2 modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_fin = [cat for expo,cat in l_couples_expo_cat_rand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne les modèles abstraits sur l'ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_lr_dbow_300_fin.fit(X_dbow_300_fin,y_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_lr_dm_300_fin.fit(X_dm_300_fin,y_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding d'un nouvel exposé des faits\n",
    "Grâce au modèle Doc2Vec déjà entraîné, on peut calculer le vecteur numérique (feature vector) d'un nouvel exposé des faits qui n'est pas dans l'ensemble d'entraînement grâce à la méthode ad-hoc **edf2vec** définie auparavant (et qui fait appel à la méthode **infer_vector** du modèle Doc2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**edf_new** est un nouvel edf (qui n'est pas dans l'ensemble d'entraînement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_new = 'Un véhicule est en panne sur la route d\\'Oron. Il bloque la voie de droite de la route.'\n",
    "#edf_new = 'Les voisins font beaucoup trop de bruit. La musique est trop forte.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v_new** est le vecteur numérique inféré pour le nouvel exposé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_new_dbow_300 = edf2vec(edf_new, model_dbow_300)\n",
    "#print(edf_new, '\\n')\n",
    "#print('Le vector inféré pour un document nouveau vaut:\\n\\n', v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_new_dm_300 = edf2vec(edf_new, model_dm_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction de la \"bonne\" catégorie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut obtenir la catégorie proposée (prédite) par le modèle LR pour le vecteur numérique correspondant au nouvel exposé **edf_new** grâce à la méthode **predict**\n",
    "\n",
    "En fait, la méthode **predict** retourne la catégorie (la classe) pour laquelle la probabilité de correspondre au nouvel exposé des faits est la plus grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_proposed_dbow_300 = model_lr_dbow_300_fin.predict([v_new_dbow_300])\n",
    "print('La catégorie proposée est pour dbow_300:', cat_proposed_dbow_300)\n",
    "#print(type(cat_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_proposed_dm_300 = model_lr_dm_300_fin.predict([v_new_dm_300])\n",
    "print('La catégorie proposée est pour dm_300:', cat_proposed_dm_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant regrouper ces opérations en une seule fonction définie ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **infer_cat** permet de déterminer la \"bonne\" catégorie pour un exposé donné et elle :\n",
    "- a comme paramètres :\n",
    "    - **expo** l'exposé des faits à classifier \n",
    "    - **model_d2v** le modèle Doc2Vec pour l'embedding (la vectorisation)\n",
    "    - **model_lr** le modèle LogisticRegression pour la classifiction multinomiale (prédiction de la catégorie)\n",
    "    - **epochs** le nombre d'époques (d'itérations) pour l'inférence du vecteur numérique    \n",
    "    - **seed** le \"seed\" pour la génération de nombres aléatoires pour le model Doc2Vec utilisé \n",
    "- affiche et retourne la \"bonne\" catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cat(expo, model_d2v, model_lr, epochs=None, seed=8017):\n",
    "    print('L\\'edf :', expo)\n",
    "    if epochs is None:\n",
    "        epochs=model_d2v.epochs\n",
    "    # on vectorise l'edf (on infère le vecteur numérique avec le modèle Doc2vec)\n",
    "    vect = edf2vec(expo, model_d2v, epochs, seed)\n",
    "    # on calcule (prédit) la \"bonne\" catégorie (avec le modèle LogisticRegression)\n",
    "    cat_proposed = model_lr.predict([vect])\n",
    "    print('La catégorie proposée est :', cat_proposed)\n",
    "    return cat_proposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des exemples d'appel de la fonction **infer_cat** pour un même exposé des faits mais pour des modèles différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_cat(edf_new, model_dbow_300, model_lr_dbow_300_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_cat(edf_new, model_dm_300, model_lr_dm_300_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction des \"meilleures\" catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu qu'assez souvent un exposé des faits n'a pas forcément une unique catégorie qui peut lui correspondre, il est judicieux de faire **plusieurs propositions** de catégories (en fonction de leurs probabilités de similarité) et pour cela on va utiliser la méthode **predict_proba**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appelée avec une matrice dont les lignes sont les feature vectors à classifier, la méthode **predict_proba** retourne aussi une matrice (un array bidimensionnel) avec le même nombre de lignes que la matrice argument et un nombre de colonnes égal au nombre de classes (chez nous des catégories) distinctes du modèle.\n",
    "\n",
    "Plus précisément, la ligne i de la matrice retournée contient les probabilités par classes correspondantes aux vecteurs numériques i de la matrice argument => la somme des éléments d'une ligne de la matrice retournée doit être égale à 1.\n",
    "\n",
    "Les classes (les catégories) distinctes sont ordonnées dans le modèle comme dans l'attribut **classes_**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un seul vecteur numérique donné en argument, la méthode **predict_proba** permet d'obtenir les probabilités qu'il soit classifié dans chacune des catégories prises en compte (et la somme de toutes ces probabilités doit valoir 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus préciséement, le résultat retourné par la méthode **predict_proba** est une matrice (tableau bidimensionnel) avec une seule ligne qui contient, dans un certain ordre, les probabilités de classification du nouvel exposé des faits dans chacune des catégories (classes) considérées "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de connaître l'ordre des catégories auxquelles correspondent les probabilités retournées par la méthode **predict_proba**, on utilise l'attribut **classes_** pour le modèle LogisticRegression employé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On explique d'abord les étapes à suivre pour le cas ***dbow_300*** et on regroupe ensuite la démarche prposée dans une fonction ad-hoc nommée **show_infer_cats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_new = 'Un véhiule est en panne sur la route d\\'Oron. Il bloque la voie de droite de la route.'\n",
    "#edf_new = 'Les voisins font beaucoup trop de bruit. La musique est trop forte.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_new = edf2vec(edf_new, model_dbow_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ll_cats_new_proba = model_lr_dbow_300_fin.predict_proba([v_new])\n",
    "print(ll_cats_new_proba[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(type(model_lr_dbow_300_fin.classes_))\n",
    "l_classes = list(model_lr_dbow_300_fin.classes_)\n",
    "print(l_classes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut maintenant ordonner de manière ***décroissante*** les probabilités retournées par la méthode **predict_proba** afin de trouver et afficher les ***meilleures*** catégories à proposer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_couples = list(enumerate(ll_cats_new_proba[0]))\n",
    "print(l_couples[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_couple_sorted = sorted(l_couples, key=lambda tup:tup[1], reverse=True)\n",
    "print(l_couple_sorted[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les meilleures propositions de catégories pour le nouvel exposé des faits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(edf_new, '\\n************************')\n",
    "print('Les catégories recommandées sont: \\n')\n",
    "for i in range(5):\n",
    "    no_cat = l_couple_sorted[i][0]\n",
    "    cat = l_classes[no_cat]\n",
    "    print(cat, ' (avec la probabilité de ', l_couple_sorted[i][1]*100, '%)')\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant regrouper les opérations précédantes en une seule fonction définie ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **show_infer_cats** permet de déterminer les \"meilleures\" catégories pour un exposé donné et elle :\n",
    "- a comme paramètres :\n",
    "    - **expo** l'exposé des faits à classifier \n",
    "    - **model_d2v** le modèle Doc2Vec pour l'embedding (la vectorisation)\n",
    "    - **epochs** le nombre d'époques (d'itérations) pour l'inférence du vecteur numérique\n",
    "    - **model_lr** le modèle LogisticRegression pour la classifiction multinomiale (prédiction de la catégorie)\n",
    "    - **nb** le nombre de \"meilleures\" catégories\n",
    "    - **seed** le \"seed\" pour la génération de nombres aléatoires pour le model Doc2Vec utilisé \n",
    "- affiche les meilleures catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_infer_cats(expo, model_d2v, model_lr, nb=5, epochs=None, seed=8017):\n",
    "    if epochs is None:\n",
    "        epochs=model_d2v.epochs\n",
    "    # on vectorise l'edf (on infère le vecteur numérique avec le modèle Doc2vec)       \n",
    "    vect = edf2vec(expo, model_d2v, epochs, seed)\n",
    "    # on calcule (prédit) le probabilités de TOUTES les catégories (avec le modèle LogisticRegression)\n",
    "    ll_cats_proba = model_lr.predict_proba([vect])\n",
    "    #print(ll_cats_proba)\n",
    "    # on associe les probabilités avec l'indice de leur apparition dans la liste précédante\n",
    "    l_couples = list(enumerate(ll_cats_proba[0]))\n",
    "    # on ordonne les probabilités de manière décroissante (en gardant leur indice initial)\n",
    "    l_couple_sorted = sorted(l_couples, key=lambda tup:tup[1], reverse=True)\n",
    "    #print(l_couple_sorted)\n",
    "    # on affiche les nb meilleures catégories avec leurs probabilités\n",
    "    print(expo, '\\n********************************************************')\n",
    "    print('Les catégories recommandées sont: \\n')\n",
    "    for i in range(nb):\n",
    "        no_cat = l_couple_sorted[i][0]\n",
    "        cat = model_lr.classes_[no_cat]\n",
    "        print(cat, ' (avec la probabilité de ', l_couple_sorted[i][1]*100, '%)')\n",
    "        print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples de prédictions des meilleures catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous, on présente des exemples de \"meilleures\" catégories prédites pour de nouveaux exposés des faits (par de simples appels de la méthode **show_infer_cats**) pour les 2 modèles LR considérés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_new = 'Un véhicule est en panne sur la route d\\'Oron. Il bloque la voie de droite de la route.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_infer_cats(edf_new, model_dbow_300, model_lr_dbow_300_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_infer_cats(edf_new, model_dm_300, model_lr_dm_300_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_new = 'Les voisins font beaucoup trop de bruit. La musique est trop forte.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_infer_cats(edf_new, model_dbow_300, model_lr_dbow_300_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_infer_cats(edf_new, model_dm_300, model_lr_dm_300_fin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
